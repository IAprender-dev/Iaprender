ENDPOINTS
Text to Speech
WebSocket
GET

wss://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream-input
Handshake
URL	wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input
Method	GET
Status	101 Switching Protocols
Try it
Messages

{"text":" ","voice_settings":{"speed":1,"stability":0.5,"similarity_boost":0.8},"xi_api_key":"<YOUR_API_KEY>"}
publish


{"text":"Hello World","try_trigger_generation":true}
publish


{"text":""}
publish


{"audio":"Y3VyaW91cyBtaW5kcyB0aGluayBhbGlrZSA6KQ==","isFinal":false,"normalizedAlignment":{"charStartTimesMs":[0,3,7,9,11,12,13,15,17,19,21],"charsDurationsMs":[3,4,2,2,1,1,2,2,2,2,3],"chars":["H","e","l","l","o"," ","w","o","r","l","d"]},"alignment":{"charStartTimesMs":[0,3,7,9,11,12,13,15,17,19,21],"charsDurationsMs":[3,4,2,2,1,1,2,2,2,2,3],"chars":["H","e","l","l","o"," ","w","o","r","l","d"]}}
subscribe

The Text-to-Speech WebSockets API is designed to generate audio from partial text input while ensuring consistency throughout the generated audio. Although highly flexible, the WebSockets API isn’t a one-size-fits-all solution. It’s well-suited for scenarios where:

The input text is being streamed or generated in chunks.
Word-to-audio alignment information is required.
However, it may not be the best choice when:

The entire input text is available upfront. Given that the generations are partial, some buffering is involved, which could potentially result in slightly higher latency compared to a standard HTTP request.
You want to quickly experiment or prototype. Working with WebSockets can be harder and more complex than using a standard HTTP API, which might slow down rapid development and testing.
Handshake
GET

wss://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream-input

Headers
xi-api-key
string
Required
Path parameters
voice_id
string
Required
The unique identifier for the voice to use in the TTS process.
Query parameters
authorization
string
Optional
Your authorization bearer token.
model_id
string
Optional
The model ID to use.
language_code
string
Optional
The ISO 639-1 language code (for specific models).

enable_logging
boolean
Optional
Defaults to true
Whether to enable logging of the request.
enable_ssml_parsing
boolean
Optional
Defaults to false
Whether to enable SSML parsing.
output_format
enum
Optional
The output audio format

Show 18 enum values
inactivity_timeout
integer
Optional
Defaults to 20
Timeout for inactivity before a context is closed (seconds), can be up to 180 seconds.

sync_alignment
boolean
Optional
Defaults to false
Whether to include timing data with every audio chunk.
auto_mode
boolean
Optional
Defaults to false
Reduces latency by disabling chunk schedule and buffers. Recommended for full sentences/phrases.

apply_text_normalization
enum
Optional
Defaults to auto
This parameter controls text normalization with three modes - ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ or ‘eleven_flash_v2_5’ models. Defaults to ‘auto’.

Allowed values:
auto
on
off
seed
integer
Optional
>=0
<=4294967295
If specified, system will best-effort sample deterministically. Integer between 0 and 4294967295.

Send
initializeConnection
object
Required

Show 6 properties
OR
sendText
object
Required

Show 5 properties
OR
closeConnection
object
Required

Show 1 properties
Receive
audioOutput
object
Required

Show 3 properties
OR
finalOutput
object
Required

Show 1 properties